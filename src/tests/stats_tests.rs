#[cfg(test)]
mod tests {
    use tempfile::NamedTempFile;
    use std::fs::File;
    use std::collections::{HashMap, HashSet};
    use std::io::{Read, Write};
    use std::path::PathBuf;
    use flate2::read::GzDecoder;

    use crate::transcripts::CdsRegion;
    use crate::parse::{parse_region, validate_vcf_header, read_reference_sequence, parse_config_file, find_vcf_file, open_vcf_reader};
    use crate::process::{
        CompressedGenotypes, MissingDataInfo, FilteringStats, PackedGenotype,
        Variant, VcfError, HaplotypeSide, Args, process_config_entries, process_variant,
        process_variants, ZeroBasedHalfOpen,
    };
    use crate::stats::{count_segregating_sites, calculate_pairwise_differences, calculate_watterson_theta, calculate_pi, harmonic, calculate_inversion_allele_frequency};

    // Helper function to create a Variant for testing
    fn create_variant(position: i64, genotypes: Vec<Option<Vec<u8>>>) -> Variant {
        let packed: Vec<Option<PackedGenotype>> = genotypes
            .into_iter()
            .map(|gt| gt.map(PackedGenotype::from_vec))
            .collect();
        Variant {
            position,
            genotypes: CompressedGenotypes::new(packed),
        }
    }

    #[test]
    fn test_missing_sites_default_to_zero_diversity() {
        // This integration test verifies that the dense writer (append_diversity_falsta)
        // correctly fills in "0" for sites that have no variants in the VCF but are within the requested region.

        // Use tempfile to create a unique directory for this test
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let temp_path = temp_dir.path();

        // 1. Setup VCF:
        // Region length 5 (1..5).
        // Only ONE variant at position 3.
        // Expected output: 0, 0, <val>, 0, 0
        let vcf_dir = temp_path.join("vcf");
        std::fs::create_dir_all(&vcf_dir).expect("failed to create vcf dir");
        let vcf_path = vcf_dir.join("chr1.vcf");
        let mut vcf_file = File::create(&vcf_path).expect("failed to create vcf");
        writeln!(vcf_file, "##fileformat=VCFv4.2").unwrap();
        writeln!(
            vcf_file,
            "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSample1"
        )
        .unwrap();
        // Variant at pos 3
        writeln!(
            vcf_file,
            "chr1\t3\t.\tA\tT\t.\tPASS\t.\tGT:GQ\t0|1:99"
        )
        .unwrap();

        // 2. Setup Reference (FASTA)
        let fasta_path = temp_path.join("reference.fa");
        let mut fasta_file = File::create(&fasta_path).expect("failed to create fasta");
        writeln!(fasta_file, ">chr1").unwrap();
        writeln!(fasta_file, "ACGTACGTAC").unwrap(); // 10 bases
        drop(fasta_file);

        let fai_path = temp_path.join("reference.fa.fai");
        let mut fai_file = File::create(&fai_path).expect("failed to create fai");
        // Name, Len, Offset, LineBases, LineWidth
        writeln!(fai_file, "chr1\t10\t6\t10\t11").unwrap();

        // 3. Setup GTF (Dummy)
        let gtf_path = temp_path.join("annotations.gtf");
        let mut gtf_file = File::create(&gtf_path).expect("failed to create gtf");
        writeln!(
            gtf_file,
            "chr1\tsource\tCDS\t1\t10\t.\t+\t0\tgene_id \"G1\"; transcript_id \"T1\";"
        )
        .unwrap();

        // 4. Setup Config
        let config_path = temp_path.join("config.tsv");
        let mut config_file = File::create(&config_path).expect("failed to create config");
        writeln!(
            config_file,
            "seqnames\tstart\tend\tPOS\torig_ID\tverdict\tcateg\tSample1"
        )
        .unwrap();
        // Request region 1-5
        writeln!(config_file, "chr1\t1\t5\t1\tid1\tpass\tinv\t0|0").unwrap();

        let config_entries = parse_config_file(&config_path).expect("failed to parse config");

        // 5. Run Process
        struct ProgressGuard;
        impl Drop for ProgressGuard {
            fn drop(&mut self) {
                crate::progress::finish_all();
            }
        }
        crate::progress::init_global_progress(config_entries.len());
        let _progress_guard = ProgressGuard;

        // Provide absolute paths to Args to avoid CWD dependency
        let args = Args {
            vcf_folder: vcf_dir.canonicalize().expect("failed to canonicalize vcf_dir").to_string_lossy().into_owned(),
            chr: None,
            region: None,
            config_file: None,
            output_file: None,
            min_gq: 30,
            mask_file: None,
            allow_file: None,
            reference_path: fasta_path.canonicalize().expect("failed to canonicalize fasta").to_string_lossy().into_owned(),
            gtf_path: gtf_path.canonicalize().expect("failed to canonicalize gtf").to_string_lossy().into_owned(),
            enable_pca: false,
            pca_components: 10,
            pca_output: "pca_results.tsv".to_string(),
            enable_fst: false,
            fst_populations: None,
            exclude: None,
        };

        let output_csv = temp_path.join("results.csv");
        let exclusion_set = HashSet::new();
        process_config_entries(
            &config_entries,
            &args.vcf_folder,
            &output_csv,
            args.min_gq,
            None,
            None,
            &args,
            &exclusion_set,
            temp_path,
        )
        .expect("process_config_entries failed");

        // 6. Verify Output
        let falsta_path = temp_dir.path().join("per_site_diversity_output.falsta.gz");
        assert!(falsta_path.exists(), "per-site falsta was not created");

        let file = File::open(&falsta_path).expect("failed to open falsta file");
        let mut decoder = GzDecoder::new(file);
        let mut contents = String::new();
        decoder.read_to_string(&mut contents).expect("failed to read falsta");

        let lines: Vec<&str> = contents.lines().collect();

        // Look for Pi of group 0 (unfiltered)
        // Header format: >unfiltered_pi_chr_1_start_1_end_5_group_0
        let pi_header = ">unfiltered_pi_chr_1_start_1_end_5_group_0";
        let pi_index = lines
            .iter()
            .position(|line| *line == pi_header)
            .expect("missing pi header in falsta");

        let pi_values: Vec<&str> = lines[pi_index + 1].split(',').collect();

        // Region is 1-5 (length 5).
        // Variant is at pos 3.
        // Expected: 0, 0, val, 0, 0
        assert_eq!(pi_values.len(), 5, "Expected 5 values for region length 5");

        assert_eq!(pi_values[0], "0", "Pos 1 should be 0");
        assert_eq!(pi_values[1], "0", "Pos 2 should be 0");
        assert_ne!(pi_values[2], "0", "Pos 3 (variant) should not be 0");
        assert_eq!(pi_values[3], "0", "Pos 4 should be 0");
        assert_eq!(pi_values[4], "0", "Pos 5 should be 0");

        // Also check Theta
        let theta_header = ">unfiltered_theta_chr_1_start_1_end_5_group_0";
        let theta_index = lines
            .iter()
            .position(|line| *line == theta_header)
            .expect("missing theta header in falsta");
        let theta_values: Vec<&str> = lines[theta_index + 1].split(',').collect();

        assert_eq!(theta_values.len(), 5);
        assert_eq!(theta_values[0], "0");
        assert_eq!(theta_values[1], "0");
        assert_ne!(theta_values[2], "0");
        assert_eq!(theta_values[3], "0");
        assert_eq!(theta_values[4], "0");
    }

    #[test]
    fn test_count_segregating_sites_with_variants() {
        let variants = vec![
            create_variant(1, vec![Some(vec![0, 0]), Some(vec![0, 1]), Some(vec![1, 1])]),
            create_variant(2, vec![Some(vec![0, 0]), Some(vec![0, 0]), Some(vec![0, 0])]),
            create_variant(3, vec![Some(vec![0, 1]), Some(vec![0, 1]), Some(vec![0, 1])]),
            create_variant(4, vec![Some(vec![0, 0]), Some(vec![1, 1]), Some(vec![0, 1])]),
        ];

        assert_eq!(count_segregating_sites(&variants), 3);
    }

    #[test]
    fn test_count_segregating_sites_no_variants() {
        assert_eq!(count_segregating_sites(&[]), 0);
    }

    #[test]
    fn test_count_segregating_sites_all_homozygous() {
        let homozygous_variants = vec![
            create_variant(1, vec![Some(vec![0, 0]), Some(vec![0, 0]), Some(vec![0, 0])]),
            create_variant(2, vec![Some(vec![1, 1]), Some(vec![1, 1]), Some(vec![1, 1])]),
        ];
        assert_eq!(count_segregating_sites(&homozygous_variants), 0);
    }

    #[test]
    fn test_count_segregating_sites_with_missing_data() {
        let missing_data_variants = vec![
            create_variant(1, vec![Some(vec![0, 0]), None, Some(vec![1, 1])]),
            create_variant(2, vec![Some(vec![0, 1]), Some(vec![0, 1]), None]),
        ];
        assert_eq!(count_segregating_sites(&missing_data_variants), 2);
    }

    #[test]
    fn test_extract_sample_id_standard_case() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id("NA12878_L"), "NA12878");
        assert_eq!(core_sample_id("NA12878_R"), "NA12878");
    }

    #[test]
    fn test_extract_sample_id_multiple_underscores() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id("SAMPLE_01_L"), "SAMPLE_01");
        assert_eq!(core_sample_id("SAMPLE_01_R"), "SAMPLE_01");
    }

    #[test]
    fn test_extract_sample_id_singlepart() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id("SAMPLE"), "SAMPLE");
        assert_eq!(core_sample_id("NoSuffix"), "NoSuffix");
    }

    #[test]
    fn test_extract_sample_id_empty_string() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id(""), "");
    }

    #[test]
    fn test_extract_sample_id_only_underscore() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id("_"), "_");
        assert_eq!(core_sample_id("_L"), "");
        assert_eq!(core_sample_id("_R"), "");
    }

    #[test]
    fn test_extract_sample_id_trailing_underscore() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id("SAMPLE_"), "SAMPLE_");
        assert_eq!(core_sample_id("SAMPLE__L"), "SAMPLE_");
        assert_eq!(core_sample_id("SAMPLE__R"), "SAMPLE_");
    }

    #[test]
    fn test_extract_sample_id_complex_names_eas() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id("HG00096_EAS_L"), "HG00096_EAS");
        assert_eq!(core_sample_id("HG00096_EAS_R"), "HG00096_EAS");
    }

    #[test]
    fn test_extract_sample_id_complex_names_amr() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id("NA19625_AMR_L"), "NA19625_AMR");
        assert_eq!(core_sample_id("NA19625_AMR_R"), "NA19625_AMR");
    }

    #[test]
    fn test_extract_sample_id_double_underscore() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id("SAMPLE__L"), "SAMPLE_");
        assert_eq!(core_sample_id("SAMPLE__R"), "SAMPLE_");
    }

    #[test]
    fn test_extract_sample_id_triple_part_name() {
        use crate::stats::core_sample_id;
        assert_eq!(core_sample_id("PART_ONE_TWO_L"), "PART_ONE_TWO");
        assert_eq!(core_sample_id("PART_ONE_TWO_R"), "PART_ONE_TWO");
    }

    #[test]
    fn test_harmonic_single() {
        assert_eq!(harmonic(1), 1.0);
    }

    #[test]
    fn test_harmonic_two() {
        assert!((harmonic(2) - 1.5).abs() < 1e-10);
    }

    #[test]
    fn test_harmonic_three() {
        let expected = 1.0 + 0.5 + 1.0/3.0;
        assert!((harmonic(3) - expected).abs() < 1e-10);
    }

    #[test]
    fn test_harmonic_ten() {
        let expected = 2.9289682539682538;
        assert!((harmonic(10) - expected).abs() < 1e-10);
    }

    #[test]
    fn test_calculate_pairwise_differences_basic() {
        let variants = vec![
            create_variant(
                1000,
                vec![Some(vec![0, 0]), Some(vec![0, 1]), Some(vec![1, 1])],
            ),
            create_variant(
                2000,
                vec![Some(vec![0, 0]), Some(vec![0, 0]), Some(vec![0, 1])],
            ),
            create_variant(
                3000,
                vec![Some(vec![0, 1]), Some(vec![1, 1]), Some(vec![0, 0])],
            ),
        ];

        let result = calculate_pairwise_differences(&variants, 3, 3);

        assert_eq!(result.len(), 3);
    }

    #[test]
    fn test_calculate_pairwise_differences_pair_0_1() {
        let variants = vec![
            create_variant(
                1000,
                vec![Some(vec![0, 0]), Some(vec![0, 1]), Some(vec![1, 1])],
            ),
            create_variant(
                2000,
                vec![Some(vec![0, 0]), Some(vec![0, 0]), Some(vec![0, 1])],
            ),
            create_variant(
                3000,
                vec![Some(vec![0, 1]), Some(vec![1, 1]), Some(vec![0, 0])],
            ),
        ];

        let result = calculate_pairwise_differences(&variants, 3, 3);

        for &((i, j), difference_count, comparable_site_count) in &result {
            if (i, j) == (0, 1) {
                assert_eq!(difference_count, 4); // Per-haplotype comparison: 2 haplotypes × 2 haplotypes = 4 comparisons
                assert_eq!(comparable_site_count, 12); // 3 genomic sites × 4 haplotype pairings
            }
        }
    }

    #[test]
    fn test_calculate_pairwise_differences_pair_0_2() {
        let variants = vec![
            create_variant(
                1000,
                vec![Some(vec![0, 0]), Some(vec![0, 1]), Some(vec![1, 1])],
            ),
            create_variant(
                2000,
                vec![Some(vec![0, 0]), Some(vec![0, 0]), Some(vec![0, 1])],
            ),
            create_variant(
                3000,
                vec![Some(vec![0, 1]), Some(vec![1, 1]), Some(vec![0, 0])],
            ),
        ];

        let result = calculate_pairwise_differences(&variants, 3, 3);

        for &((i, j), difference_count, comparable_site_count) in &result {
            if (i, j) == (0, 2) {
                assert_eq!(difference_count, 8); // Per-haplotype comparison across 3 variants
                assert_eq!(comparable_site_count, 12);
            }
        }
    }

    #[test]
    fn test_calculate_pairwise_differences_with_missing_data() {
        let missing_data_variants = vec![
            create_variant(1, vec![Some(vec![0]), None, Some(vec![1])]),
            create_variant(2, vec![Some(vec![1]), Some(vec![1]), None]),
        ];
        let missing_data_result = calculate_pairwise_differences(&missing_data_variants, 3, 2);

        assert_eq!(missing_data_result.len(), 3);

        for &((i, j), count, comparable_sites) in &missing_data_result {
            match (i, j) {
                (0, 1) => {
                    assert_eq!(count, 0);
                    assert_eq!(comparable_sites, 1); // One site dropped due to missing data
                }
                (0, 2) => {
                    assert_eq!(count, 1);
                    assert_eq!(comparable_sites, 1); // One site dropped due to missing data
                }
                (1, 2) => {
                    assert_eq!(count, 0);
                    assert_eq!(comparable_sites, 0); // Both sites missing for the pair
                }
                _ => panic!("Unexpected pair: ({}, {})", i, j),
            }
        }
    }

    #[test]
    fn test_calculate_watterson_theta_case1() {
        let epsilon = 1e-6;
        assert!((calculate_watterson_theta(10, 5, 1000) - 0.0048).abs() < epsilon);
    }

    #[test]
    fn test_calculate_watterson_theta_case2() {
        let epsilon = 1e-6;
        assert!((calculate_watterson_theta(5, 2, 1000) - 0.005).abs() < epsilon);
    }

    #[test]
    fn test_calculate_watterson_theta_large_values() {
        let epsilon = 1e-6;
        assert!((calculate_watterson_theta(100, 10, 1_000_000) - 0.00003534).abs() < epsilon);
    }

    #[test]
    fn test_calculate_watterson_theta_n1() {
        let theta_n1 = calculate_watterson_theta(100, 1, 1000);
        assert!(theta_n1.is_infinite());
    }

    #[test]
    fn test_calculate_watterson_theta_n0() {
        let theta_n0 = calculate_watterson_theta(0, 0, 1000);
        assert!(theta_n0.is_nan()); // n=0, seg_sites=0 should return NaN
    }

    #[test]
    fn test_calculate_watterson_theta_seq_zero() {
        let theta_seq_zero = calculate_watterson_theta(10, 5, 0);
        assert!(theta_seq_zero.is_infinite());
    }

    #[test]
    fn test_calculate_watterson_theta_pi_typical() {
        let variants = vec![
            create_variant(100, vec![Some(vec![0, 1]), Some(vec![1, 0])]),
            create_variant(200, vec![Some(vec![0, 0]), Some(vec![1, 1])]),
        ];
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right), (1, HaplotypeSide::Left), (1, HaplotypeSide::Right)];
        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert!(pi > 0.0);
    }

    #[test]
    fn test_calculate_watterson_theta_pi_no_differences() {
        let variants = vec![
            create_variant(100, vec![Some(vec![0, 0]), Some(vec![0, 0])]),
            create_variant(200, vec![Some(vec![1, 1]), Some(vec![1, 1])]),
        ];
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right), (1, HaplotypeSide::Left), (1, HaplotypeSide::Right)];
        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert_eq!(pi, 0.0);
    }

    #[test]
    fn test_calculate_pi_no_variants_returns_zero() {
        let variants = vec![];
        let haplotypes = vec![
            (0, HaplotypeSide::Left),
            (0, HaplotypeSide::Right),
        ];
        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert_eq!(pi, 0.0);
    }

    #[test]
    fn test_calculate_watterson_theta_pi_min_sample_size() {
        let variants = vec![create_variant(100, vec![Some(vec![0, 1])])];
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right)];
        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert!(pi >= 0.0);
    }

    #[test]
    fn test_calculate_watterson_theta_pi_n1_nan() {
        let variants = vec![create_variant(100, vec![Some(vec![0, 1])])];
        let haplotypes = vec![(0, HaplotypeSide::Left)];
        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert!(pi.is_nan()); // Single haplotype has insufficient data
    }

    #[test]
    fn test_calculate_watterson_theta_pi_seq_zero() {
        let variants = vec![create_variant(100, vec![Some(vec![0, 1]), Some(vec![1, 0])])];
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right), (1, HaplotypeSide::Left), (1, HaplotypeSide::Right)];
        let pi = calculate_pi(&variants, &haplotypes, 0);
        assert!(pi.is_infinite() || pi.is_nan()); // Division by zero sequence length
    }

    #[test]
    fn test_calculate_watterson_theta_pi_large_values() {
        let mut variants = Vec::new();
        for i in 0..100 {
            variants.push(create_variant(i * 10, vec![Some(vec![0, 1]), Some(vec![1, 0])]));
        }
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right), (1, HaplotypeSide::Left), (1, HaplotypeSide::Right)];
        let pi = calculate_pi(&variants, &haplotypes, 1000000);
        assert!(pi > 0.0 && pi < 1.0);
    }

    #[test]
    fn test_calculate_pi_typical_values() {
        // Create test variants with some differences
        let variants = vec![
            create_variant(100, vec![Some(vec![0, 1]), Some(vec![1, 0])]), // Different
            create_variant(200, vec![Some(vec![0, 0]), Some(vec![1, 1])]), // Different
        ];
        
        // Create haplotype group with 2 samples (4 haplotypes total)
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right), (1, HaplotypeSide::Left), (1, HaplotypeSide::Right)];
        
        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert!(pi > 0.0); // Should have some diversity
    }

    #[test]
    fn test_calculate_pi_no_pairwise_differences() {
        // Create test variants with no differences (all same)
        let variants = vec![
            create_variant(100, vec![Some(vec![0, 0]), Some(vec![0, 0])]), // Same
            create_variant(200, vec![Some(vec![1, 1]), Some(vec![1, 1])]), // Same
        ];

        // Create haplotype group
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right), (1, HaplotypeSide::Left), (1, HaplotypeSide::Right)];

        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert_eq!(pi, 0.0); // No diversity
    }

    #[test]
    fn test_calculate_pi_excludes_uncallable_sites_from_denominator() {
        let variants = vec![
            create_variant(10, vec![Some(vec![0, 0]), Some(vec![1, 1])]),
            create_variant(20, vec![None, None]),
        ];

        let haplotypes = vec![
            (0, HaplotypeSide::Left),
            (0, HaplotypeSide::Right),
            (1, HaplotypeSide::Left),
            (1, HaplotypeSide::Right),
        ];

        let pi = calculate_pi(&variants, &haplotypes, 2);
        let expected = 2.0 / 3.0;
        assert!((pi - expected).abs() < 1e-9, "expected π ≈ {}, observed {}", expected, pi);
    }

    #[test]
    fn test_calculate_pi_large_pairwise_differences() {
        let mut variants = Vec::new();
        for i in 0..50 {
            variants.push(create_variant(i * 20, vec![Some(vec![0, 1]), Some(vec![1, 0]), Some(vec![1, 1])]));
        }
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right), (1, HaplotypeSide::Left), (1, HaplotypeSide::Right), (2, HaplotypeSide::Left), (2, HaplotypeSide::Right)];
        let pi = calculate_pi(&variants, &haplotypes, 10000);
        assert!(pi > 0.0);
    }

    #[test]
    fn test_calculate_pi_min_sample_size() {
        let variants = vec![create_variant(100, vec![Some(vec![0, 1])])];
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right)];
        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert!(pi >= 0.0);
    }

    #[test]
    fn test_calculate_pi_very_large_sequence_length() {
        let variants = vec![create_variant(100, vec![Some(vec![0, 1]), Some(vec![1, 0])])];
        let haplotypes = vec![(0, HaplotypeSide::Left), (0, HaplotypeSide::Right), (1, HaplotypeSide::Left), (1, HaplotypeSide::Right)];
        let pi = calculate_pi(&variants, &haplotypes, 1_000_000_000);
        assert!(pi > 0.0 && pi < 0.001); // Very small due to large sequence length
    }

    #[test]
    fn test_calculate_pi_n1_nan() {
        let variants = vec![create_variant(100, vec![Some(vec![0, 1])])];
        let haplotypes = vec![(0, HaplotypeSide::Left)];
        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert!(pi.is_nan()); // Single haplotype has insufficient data
    }

    #[test]
    fn test_calculate_pi_n0_nan() {
        let variants = vec![create_variant(100, vec![Some(vec![0, 1])])];
        let haplotypes = vec![]; // No haplotypes
        let pi = calculate_pi(&variants, &haplotypes, 1000);
        assert!(pi.is_nan()); // No haplotypes means statistic is undefined
    }

    #[test]
    fn test_parse_region_valid_small() {
        let result = parse_region("1-1000").unwrap();
        assert_eq!(result.start, 0); // 1-based to 0-based
        assert_eq!(result.end, 1000);
    }

    #[test]
    fn test_parse_region_valid_large() {
        let result = parse_region("1000000-2000000").unwrap();
        assert_eq!(result.start, 999999); // 1-based to 0-based
        assert_eq!(result.end, 2000000);
    }

    #[test]
    fn test_parse_region_invalid_missing_end() {
        assert!(matches!(parse_region("1000"), Err(VcfError::InvalidRegion(_))));
    }

    #[test]
    fn test_parse_region_invalid_missing_start() {
        assert!(matches!(parse_region("1000-"), Err(VcfError::InvalidRegion(_))));
    }

    #[test]
    fn test_parse_region_invalid_negative_start() {
        assert!(matches!(parse_region("-1000"), Err(VcfError::InvalidRegion(_))));
    }

    #[test]
    fn test_parse_region_invalid_non_numeric_start() {
        assert!(matches!(parse_region("a-1000"), Err(VcfError::InvalidRegion(_))));
    }

    #[test]
    fn test_parse_region_invalid_non_numeric_end() {
        assert!(matches!(parse_region("1000-b"), Err(VcfError::InvalidRegion(_))));
    }

    #[test]
    fn test_parse_region_invalid_start_equals_end() {
        assert!(matches!(parse_region("1000-1000"), Err(VcfError::InvalidRegion(_))));
    }

    #[test]
    fn test_parse_region_invalid_start_greater_than_end() {
        assert!(matches!(parse_region("2000-1000"), Err(VcfError::InvalidRegion(_))));
    }

    #[test]
    fn test_validate_vcf_header_valid() {
        let valid_header = "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1\tSAMPLE2";
        assert!(validate_vcf_header(valid_header).is_ok());
    }

    #[test]
    fn test_validate_vcf_header_invalid_missing_fields() {
        let invalid_header = "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO";
        assert!(matches!(validate_vcf_header(invalid_header), Err(VcfError::InvalidVcfFormat(_))));
    }

    #[test]
    fn test_validate_vcf_header_invalid_order() {
        let invalid_order = "POS\t#CHROM\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT";
        assert!(matches!(validate_vcf_header(invalid_order), Err(VcfError::InvalidVcfFormat(_))));
    }
    




    #[test]
    fn test_process_variants_with_invalid_haplotype_group() {
        let variants = vec![
            create_variant(1000, vec![Some(vec![0, 0]), Some(vec![0, 1]), Some(vec![1, 1])]),
            create_variant(2000, vec![Some(vec![0, 0]), Some(vec![0, 0]), Some(vec![0, 1])]),
            create_variant(3000, vec![Some(vec![0, 1]), Some(vec![1, 1]), Some(vec![0, 0])]),
        ];
        let sample_names = vec!["SAMPLE1".to_string(), "SAMPLE2".to_string(), "SAMPLE3".to_string()];
        let mut sample_filter = HashMap::new();
        sample_filter.insert("SAMPLE1".to_string(), (0, 1));
        sample_filter.insert("SAMPLE2".to_string(), (0, 1));
        sample_filter.insert("SAMPLE3".to_string(), (0, 1));
        let adjusted_sequence_length: Option<i64> = None;
        let chromosome = "1".to_string();

        // Read reference sequence
        let (fasta_file, _cds_regions) = setup_test_data();
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");

        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('C', vec!['G'])),
            Some(('G', vec!['A'])),
        ];

        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let invalid_group = process_variants(
            &variants,
            &sample_names,
            2, // haplotype_group=2 (invalid, since only 0 and 1)
            &sample_filter,
            ZeroBasedHalfOpen { start: 999, end: 3001 },
            ZeroBasedHalfOpen { start: 999, end: 3001 },
            adjusted_sequence_length,
            &allele_infos,
            chromosome.clone(),
            false, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        );
        assert!(invalid_group.unwrap_or(None).is_none(), "Expected None for invalid haplotype group");
    }

    #[test]
    fn test_parse_config_file_with_noreads() {
        let config_content = "seqnames\tstart\tend\tPOS\torig_ID\tverdict\tcateg\tSAMPLE1\tSAMPLE2\n\
                              chr1\t1000\t2000\t1500\ttest_id\tpass\tinv\t0|1_lowconf\t1|1\n\
                              chr1\t3000\t4000\t.\t.\t.\t.\t0|0\t0|1\n";
        let path = NamedTempFile::new().expect("Failed to process variants");
        write!(path.as_file(), "{}", config_content).expect("Failed to process variants");

        let config_entries = parse_config_file(path.path()).expect("Failed to process variants");
        assert_eq!(config_entries.len(), 2);
    }

    #[test]
    fn test_find_vcf_file_existing_vcfs() {
        use std::fs::File;

        // Create a temporary directory for testing
        let temp_dir = tempfile::tempdir().expect("Failed to process variants");
        let temp_path = temp_dir.path();

        // Create some test VCF files
        File::create(temp_path.join("chr1.vcf")).expect("Failed to process variants");
        File::create(temp_path.join("chr2.vcf.gz")).expect("Failed to process variants");
        File::create(temp_path.join("chr10.vcf")).expect("Failed to process variants");

        // Test finding existing VCF files
        let vcf1 = find_vcf_file(temp_path.to_str().unwrap(), "1").expect("Failed to process variants");
        assert!(vcf1.ends_with("chr1.vcf"));

        let vcf2 = find_vcf_file(temp_path.to_str().unwrap(), "2").expect("Failed to process variants");
        assert!(vcf2.ends_with("chr2.vcf.gz"));

        let vcf10 = find_vcf_file(temp_path.to_str().unwrap(), "10").expect("Failed to process variants");
        assert!(vcf10.ends_with("chr10.vcf"));
    }

    #[test]
    fn test_find_vcf_file_non_existent_chromosome() {
        use std::fs::File;

        // Create a temporary directory for testing
        let temp_dir = tempfile::tempdir().expect("Failed to process variants");
        let temp_path = temp_dir.path();

        // Create some test VCF files
        File::create(temp_path.join("chr1.vcf")).expect("Failed to process variants");
        File::create(temp_path.join("chr2.vcf.gz")).expect("Failed to process variants");
        File::create(temp_path.join("chr10.vcf")).expect("Failed to process variants");

        // Test with non-existent chromosome "3"
        let result = find_vcf_file(temp_path.to_str().unwrap(), "3");
        assert!(matches!(result, Err(VcfError::NoVcfFiles)));
    }

    #[test]
    fn test_find_vcf_file_non_existent_directory() {
        // Test with a non-existent directory path
        let result = find_vcf_file("/non/existent/path", "1");
        assert!(result.is_err());
    }

    #[test]
    fn test_open_vcf_reader_non_existent_file() {
        let path = PathBuf::from("/non/existent/file.vcf");
        let result = open_vcf_reader(&path);
        assert!(result.is_err());
    }

    #[test]
    fn test_open_vcf_reader_uncompressed_file() {
        // Create a temporary uncompressed VCF file
        let temp_file = NamedTempFile::new().expect("Failed to process variants");
        let path = temp_file.path();
        let mut file = File::create(path).expect("Failed to process variants");
        writeln!(file, "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1").expect("Failed to process variants");

        let reader = open_vcf_reader(&path);
        assert!(reader.is_ok());
    }

    #[test]
    fn test_open_vcf_reader_gzipped_file() {
        // Create a temporary gzipped VCF file
        let gzipped_file = NamedTempFile::new().expect("Failed to process variants");
        let path = gzipped_file.path();
        let mut encoder = flate2::write::GzEncoder::new(File::create(path).unwrap(), flate2::Compression::default());
        writeln!(encoder, "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSAMPLE1").expect("Failed to process variants");
        encoder.finish().expect("Failed to process variants");

        let reader = open_vcf_reader(&path);
        assert!(reader.is_ok());
    }

    #[test]
    fn test_gq_filtering_low_gq_variant() {
        let sample_names = vec![
            "SAMPLE1".to_string(),
            "SAMPLE2".to_string(),
        ];
        let mut missing_data_info = MissingDataInfo::default();
        let mut filtering_stats = FilteringStats::default();
        let min_gq = 30;
        let _mask: Option<&[(i64, i64)]> = None;
    
        // Define the expected variant using the helper function
        let expected_variant = create_variant(
            999, // VCF position 1000 becomes 0-based position 999
            vec![
                Some(vec![0, 0]), // SAMPLE1: 0|0:20 (below threshold)
                Some(vec![0, 1]), // SAMPLE2: 0|1:40
            ],
        );
    
        // VCF line with one genotype below the GQ threshold
        let variant_line = "chr1\t1000\t.\tA\tT\t.\tPASS\t.\tGT:GQ\t0|0:20\t0|1:40";
        let region = ZeroBasedHalfOpen { start: 999, end: 2000 };
        let regions = [region];
        let indices = vec![9, 10];
        let result = process_variant(
            variant_line,
            "1",
            &regions,
            &mut missing_data_info,
            &sample_names,
            &indices,
            min_gq,
            &mut filtering_stats,
            None,
            None,
        );

        // the function executed without errors
        assert!(result.is_ok());

        // Assert that the variant is returned but marked as invalid (filtered out)
        // flags != 0 means invalid
        let (variant, flags, info) = result.unwrap().unwrap();
        assert_eq!(variant, expected_variant);
        assert_ne!(flags, 0);
        assert_eq!(info, Some((999, 'A', vec!['T'])));
    }

    #[test]
    fn test_gq_filtering_valid_variant() {
        let sample_names = vec!["Sample1".to_string(), "Sample2".to_string()];
        let mut missing_data_info = MissingDataInfo::default();  
        let mut _filtering_stats = FilteringStats::default();
        let min_gq = 30;
        let _mask: Option<&[(i64, i64)]> = None;

        let valid_variant_line = "chr1\t1000\t.\tA\tT\t.\tPASS\t.\tGT:GQ\t0|0:35\t0|1:40";
        let region = ZeroBasedHalfOpen { start: 999, end: 2000 };
        let regions = [region];
        let indices = vec![9, 10];
        let result = process_variant(
            valid_variant_line,
            "1",
            &regions,
            &mut missing_data_info,
            &sample_names,
            &indices,
            min_gq,
            &mut _filtering_stats,
            None,
            None,
        ).expect("Failed to process variants");

        // Variant should be Some because all samples have GQ >= min_gq
        assert!(result.is_some());

        if let Some((variant, flags, allele_info)) = result {
            assert_eq!(flags, 0); // 0 means valid (FLAG_PASS)
            let expected: Vec<Option<PackedGenotype>> = vec![
                Some(PackedGenotype::from_vec(vec![0, 0])),
                Some(PackedGenotype::from_vec(vec![0, 1])),
            ];
            let actual: Vec<Option<PackedGenotype>> =
                (0..variant.genotypes.len()).map(|idx| variant.genotypes.get(idx)).collect();
            assert_eq!(actual, expected);
            assert_eq!(allele_info, Some((999, 'A', vec!['T'])));
        } else {
            panic!("Expected Some variant, got None");
        }
    }
    

    
    fn setup_test_data() -> (NamedTempFile, Vec<CdsRegion>) {
        let mut fasta_file = NamedTempFile::new().expect("Failed to create temporary fasta file");
    
        // Write a simple sequence that's long enough to test anything
        let sequence = "ACGT".repeat(10000);
        writeln!(fasta_file, ">1").expect("Failed to write FASTA header");
        writeln!(fasta_file, "{}", sequence).expect("Failed to write sequence");
        fasta_file.flush().expect("Failed to flush file");
        
        // Create FASTA index file
        let fasta_path = fasta_file.path();
        let index_path = format!("{}.fai", fasta_path.display());
        let mut index_file = std::fs::File::create(&index_path).expect("Failed to create index file");
        
        // Write index entry: NAME\tLENGTH\tOFFSET\tLINEBASES\tLINEWIDTH
        // For our simple FASTA: chromosome "1", length 40000, offset 3 (after ">1\n"), 40000 bases per line, 40001 chars per line (including newline)
        writeln!(index_file, "1\t{}\t3\t{}\t{}", sequence.len(), sequence.len(), sequence.len() + 1)
            .expect("Failed to write index");
        index_file.flush().expect("Failed to flush index file");
    
        let cds_regions = vec![
            CdsRegion { 
                transcript_id: "test1".to_string(), 
                segments: vec![(1200, 1901, '+', 0)] 
            },
            CdsRegion { 
                transcript_id: "test2".to_string(), 
                segments: vec![(1950, 2113, '+', 0)] 
            },
            CdsRegion { 
                transcript_id: "test3".to_string(), 
                segments: vec![(2600, 2679, '+', 0)] 
            },
        ];
    
        (fasta_file, cds_regions)
    }


    // Setup function for Group 1 tests
    fn setup_group1_test() -> (Vec<Variant>, Vec<String>, HashMap<String, (u8, u8)>) {
        // Define the sample names as they appear in the VCF.
        let sample_names = vec![
            "Sample1".to_string(),
            "Sample2".to_string(),
            "Sample3".to_string(),
        ];
    
        // Define the sample_filter for haplotype_group=1.
        // Each entry maps a sample to its (left_haplotype, right_haplotype) group assignments.
        // To achieve an allele frequency of 2/3 for Group 1, configure as follows:
        // - Sample1: left=0 (direct), right=1 (inversion)
        // - Sample2: left=1 (inversion), right=0 (direct)
        // - Sample3: left=0 (direct), right=1 (inversion)
        let sample_filter = HashMap::from([
            ("Sample1".to_string(), (0, 1)), // haplotype_group=1: 1
            ("Sample2".to_string(), (1, 0)), // haplotype_group=1: 0
            ("Sample3".to_string(), (0, 1)), // haplotype_group=1: 1
        ]);
    
        // Define the variants within the region 1000 to 3000.
        // Each variant includes:
        // - Position on the chromosome.
        // - Genotypes for each sample, represented as Option<Vec<u8>>:
        //     - `Some(vec![allele1, allele2])` for valid genotypes.
        //     - `None` for missing genotypes.
        let variants = vec![
            // Variant at position 1000
            create_variant(
                1000,
                vec![
                    Some(vec![0, 0]), // Sample1: 0|0
                    Some(vec![0, 1]), // Sample2: 0|1
                    Some(vec![1, 1]), // Sample3: 1|1
                ],
            ),
            // Variant at position 2000 (all genotypes are 0|0)
            create_variant(
                2000,
                vec![
                    Some(vec![0, 0]), // Sample1: 0|0
                    Some(vec![0, 0]), // Sample2: 0|0
                    Some(vec![0, 0]), // Sample3: 0|0
                ],
            ),
            // Variant at position 3000
            create_variant(
                3000,
                vec![
                    Some(vec![0, 1]), // Sample1: 0|1
                    Some(vec![1, 1]), // Sample2: 1|1
                    Some(vec![0, 0]), // Sample3: 0|0
                ],
            ),
        ];
    
        // Return the setup tuple containing variants, sample names, and sample_filter.
        (variants, sample_names, sample_filter)
    }

    // Setup function for global tests
    fn setup_global_test() -> (Vec<Variant>, Vec<String>, HashMap<String, (u8, u8)>) {
        // Define the sample names as they appear in the VCF.
        let sample_names = vec![
            "Sample1".to_string(),
            "Sample2".to_string(),
            "Sample3".to_string(),
        ];
    
        // Define the sample_filter for haplotype_group=1.
        // Each entry maps a sample to its (left_haplotype, right_haplotype) group assignments.
        // To achieve an allele frequency of 2/3 for Group 1, configure as follows:
        // - Sample1: left=0 (direct), right=1 (inversion)
        // - Sample2: left=1 (inversion), right=0 (direct)
        // - Sample3: left=0 (direct), right=1 (inversion)
        let sample_filter = HashMap::from([
            ("Sample1".to_string(), (0, 1)), // haplotype_group=1: 1
            ("Sample2".to_string(), (1, 0)), // haplotype_group=1: 0
            ("Sample3".to_string(), (0, 1)), // haplotype_group=1: 1
        ]);
    
        // Define the variants within the region 1000 to 3000.
        // Each variant includes:
        // - Position on the chromosome.
        // - Genotypes for each sample, represented as Option<Vec<u8>>:
        //     - `Some(vec![allele1, allele2])` for valid genotypes.
        //     - `None` for missing genotypes.
        let variants = vec![
            // Variant at position 1000
            create_variant(
                1000,
                vec![
                    Some(vec![0, 0]), // Sample1: 0|0
                    Some(vec![0, 1]), // Sample2: 0|1
                    Some(vec![1, 1]), // Sample3: 1|1
                ],
            ),
            // Variant at position 2000 (all genotypes are 0|0)
            create_variant(
                2000,
                vec![
                    Some(vec![0, 0]), // Sample1: 0|0
                    Some(vec![0, 0]), // Sample2: 0|0
                    Some(vec![0, 0]), // Sample3: 0|0
                ],
            ),
            // Variant at position 3000
            create_variant(
                3000,
                vec![
                    Some(vec![0, 1]), // Sample1: 0|1
                    Some(vec![1, 1]), // Sample2: 1|1
                    Some(vec![0, 0]), // Sample3: 0|0
                ],
            ),
        ];
    
        // Return the setup tuple containing variants, sample names, and sample_filter.
        (variants, sample_names, sample_filter)
    }

    #[test]
    fn test_allele_frequency() {
        let sample_names = vec![
            "SAMPLE1".to_string(),
            "SAMPLE2".to_string(),
            "SAMPLE3".to_string(),
        ];
        let mut sample_filter = HashMap::new();
        sample_filter.insert("SAMPLE1".to_string(), (0, 1));
        sample_filter.insert("SAMPLE2".to_string(), (0, 1));
        sample_filter.insert("SAMPLE3".to_string(), (0, 1));
        let adjusted_sequence_length: Option<i64> = Some(2001);
        let chromosome = "1".to_string();
        let (fasta_file, _cds_regions) = setup_test_data();
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");
    
        // Define VCF lines as strings
        let vcf_lines = vec![
            "chr1\t1000\t.\tA\tT\t.\tPASS\t.\tGT:GQ\t0|0:35\t0|1:40\t1|1:45",
            "chr1\t2000\t.\tA\tA\t.\tPASS\t.\tGT:GQ\t0|0:35\t0|0:40\t0|0:45",
            "chr1\t3000\t.\tA\tT\t.\tPASS\t.\tGT:GQ\t0|1:35\t1|1:40\t0|0:45",
        ];
    
        let indices = vec![9, 10, 11];
        // Parse each VCF line to populate `position_allele_map`
        for line in &vcf_lines {
            let mut missing_data_info = MissingDataInfo::default();
            let mut filtering_stats = FilteringStats::default();
            let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
            let regions = [region];
            let result = process_variant(
                line,
                "1",
                &regions,
                &mut missing_data_info,
                &sample_names,
                &indices,
                30,
                &mut filtering_stats,
                None,
                None,
            );
            assert!(result.is_ok(), "Failed to process variant: {}", line);
        }
    
        // Now, process the variants
        let variants = vec![
            create_variant(1000, vec![Some(vec![0, 0]), Some(vec![0, 1]), Some(vec![1, 1])]),
            create_variant(2000, vec![Some(vec![0, 0]), Some(vec![0, 0]), Some(vec![0, 0])]),
            create_variant(3000, vec![Some(vec![0, 1]), Some(vec![1, 1]), Some(vec![0, 0])]),
        ];
        
        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('C', vec!['G'])),
            Some(('G', vec!['A'])),
        ];
    
        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let result = process_variants(
            &variants,
            &sample_names,
            0, // haplotype_group is irrelevant now
            &sample_filter,
            ZeroBasedHalfOpen { start: 999, end: 3001 },
            ZeroBasedHalfOpen { start: 999, end: 3001 },
            adjusted_sequence_length,
            &allele_infos,
            chromosome.clone(),
            false, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        ).unwrap();
    
        // Calculate allele frequency globally
        let allele_frequency = calculate_inversion_allele_frequency(&sample_filter);
    
        // Calculate expected allele frequency
        let expected_freq = 0.5; // Based on test setup
        let allele_frequency_diff = (allele_frequency.unwrap_or(0.0) - expected_freq).abs();
        println!(
            "Allele frequency difference: {}",
            allele_frequency_diff
        );
        assert!(
            allele_frequency_diff < 1e-6,
            "Allele frequency is incorrect: expected {:.6}, got {:.6}",
            expected_freq,
            allele_frequency.unwrap_or(0.0)
        );
    
        // Verify segregating sites
        assert_eq!(result.unwrap().0, 2, "Number of segregating sites should be 2");
    }

    #[test]
    fn test_group1_number_of_haplotypes() {
        let (variants, sample_names, sample_filter) = setup_group1_test();
        let adjusted_sequence_length: Option<i64> = None;
        let chromosome = "1".to_string();
        let (fasta_file, _cds_regions) = setup_test_data();
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");
        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('C', vec!['G'])),
            Some(('G', vec!['A'])),
        ];
    
        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let _result_group1 = process_variants(
            &variants,
            &sample_names,
            1, // haplotype_group=1
            &sample_filter,
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            adjusted_sequence_length,
            &allele_infos,
            chromosome.clone(),
            false, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        ).unwrap();
    
        let (_segsites, _w_theta, _pi, n_hap, _site_diversity) = match _result_group1 {
            Some(data) => data,
            None => panic!("Expected Some variant data"),
        };
    
        // Number of haplotypes for group1 should be 3
        let expected_num_hap_group1 = 3;
        println!(
            "Number of haplotypes for Group 1 (expected {}): {}",
            expected_num_hap_group1, n_hap
        );
        assert_eq!(
            n_hap, expected_num_hap_group1,
            "Number of haplotypes for Group 1 is incorrect: expected {}, got {}",
            expected_num_hap_group1, n_hap
        );
    }

    #[test]
    fn test_group1_segregating_sites() {
        let (variants, sample_names, sample_filter) = setup_group1_test();
        
        // First, test the basic count_segregating_sites function directly
        let direct_count = count_segregating_sites(&variants);
        println!("Direct count_segregating_sites result: {}", direct_count);
        println!("Variants: {:?}", variants);
        let adjusted_sequence_length: Option<i64> = None;
        let _mask: Option<&[(i64, i64)]> = None;
        let mut _filtering_stats = FilteringStats::default();
        let chromosome = "1".to_string();
    
        // Adjusted CDS regions
        let (fasta_file, _cds_regions) = setup_test_data();
    
        // Read reference sequence covering the CDS regions
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");
    
        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('C', vec!['G'])),
            Some(('G', vec!['A'])),
        ];
    
        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let _result_group1 = process_variants(
            &variants,
            &sample_names,
            1, // haplotype_group=1
            &sample_filter,
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            adjusted_sequence_length,
            &allele_infos,
            chromosome.clone(),
            true, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        ).unwrap();

        // Correctly unwrap the Option to access the inner tuple
        let (segsites, _w_theta, _pi, _n_hap, _site_diversity) = match _result_group1 {
            Some(data) => data,
            None => panic!("Expected Some variant data"),
        };

        let expected_segsites_group1 = 2;
        println!(
            "Number of segregating sites for Group 1 (expected {}): {}",
            expected_segsites_group1, segsites
        );
        assert_eq!(
            segsites, expected_segsites_group1,
            "Number of segregating sites for Group 1 is incorrect: expected {}, got {}",
            expected_segsites_group1, segsites
        );
    }

    #[test]
    fn test_watterson_theta_exact_h4() {
       let variants = vec![
           create_variant(1000, vec![
               Some(vec![0, 1]), // Sample1: 0|1
               Some(vec![1, 0]), // Sample2: 1|0
           ]),
           create_variant(2000, vec![
               Some(vec![1, 1]), // Sample1: 1|1 
               Some(vec![0, 0]), // Sample2: 0|0
           ]),
       ];
       let sample_names = vec!["Sample1".to_string(), "Sample2".to_string()];
       let sample_filter = HashMap::from([
           ("Sample1".to_string(), (1, 1)), // Add both haplotypes to group 1
           ("Sample2".to_string(), (1, 1)), // Add both haplotypes to group 1
       ]);
       let chromosome = "1".to_string();
       let (fasta_file, _cds_regions) = setup_test_data();
       let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
       let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
           .expect("Failed to read reference sequence");

       let allele_infos = vec![
           Some(('A', vec!['G'])),
           Some(('T', vec!['C'])),
       ];
    
       let empty_filtered_positions = HashSet::new();
       let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
       let result = process_variants(
           &variants,
           &sample_names,
           1,  // haplotype_group=1
           &sample_filter,
           ZeroBasedHalfOpen { start: 999, end: 2001 }, // Include position 2000
           ZeroBasedHalfOpen { start: 999, end: 2001 }, // Include position 2000
           Some(100),  // sequence_length=100 for some reason
           &allele_infos,
           chromosome,
           false,
           &reference_sequence,
           &vec![], // Empty TranscriptAnnotationCDS for test
           &empty_filtered_positions,
            None,
           temp_dir.path(),
           None, None, None,
       ).unwrap();
    
       let (segsites, w_theta, _pi, n_hap, _site_diversity) = match result {
           Some(data) => data,
           None => panic!("Expected Some variant data"),
       };
    
       // n=4 haplotypes means we sum 1/1 + 1/2 + 1/3 = 11/6
       // theta = 2 / (11/6) / 100 = 12/11/100
       let expected_theta = 12.0/11.0/100.0;
       println!("Got {} segregating sites with {} haplotypes", segsites, n_hap);
       println!("Expected theta: {:.8}, Actual theta: {:.8}, Difference: {:.8}", 
                expected_theta, w_theta, (w_theta - expected_theta).abs());
       assert!((w_theta - expected_theta).abs() < 1e-10);
    }
    
    #[test]
    fn test_group1_watterson_theta() {
        let (variants, sample_names, sample_filter) = setup_group1_test();
        let adjusted_sequence_length: Option<i64> = None;
        let _mask: Option<&[(i64, i64)]> = None;
        let mut _filtering_stats = FilteringStats::default();
        let chromosome = "1".to_string();
        let (fasta_file, _cds_regions) = setup_test_data();
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");
        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('C', vec!['G'])),
            Some(('G', vec!['A'])),
        ];
    
        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let _result_group1 = process_variants(
            &variants,
            &sample_names,
            1, // haplotype_group=1
            &sample_filter,
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            adjusted_sequence_length,
            &allele_infos,
            chromosome.clone(),
            false, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        ).unwrap();
    
        // Correctly unwrap the Option to access the inner tuple
        let (_segsites, w_theta, _pi, _n_hap, _site_diversity) = match _result_group1 {
            Some(data) => data,
            None => panic!("Expected Some variant data"),
        };
    
        // Calculate expected Watterson's theta
        let harmonic_value = harmonic(2); // n-1 =2
        let expected_w_theta = 2.0 / harmonic_value / 2001.0;
    
        let w_theta_diff = (w_theta - expected_w_theta).abs();
        println!(
            "Watterson's theta difference for Group 1: {}",
            w_theta_diff
        );
        assert!(
            w_theta_diff < 1e-6,
            "Watterson's theta for Group 1 is incorrect: expected {:.6}, got {:.6}",
            expected_w_theta,
            w_theta
        );
    }

    #[test]
    fn test_global_allele_frequency_filtered() {
        let (variants, sample_names, sample_filter) = setup_global_test();
        let adjusted_sequence_length = Some(2001); // seq_length = 2001
        let chromosome = "1".to_string();
        let (fasta_file, _cds_regions) = setup_test_data();
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");

        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('A', vec!['A'])),
            Some(('A', vec!['T'])),
        ];

        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let result = process_variants(
            &variants,
            &sample_names,
            0, // haplotype_group is irrelevant now
            &sample_filter,
            ZeroBasedHalfOpen { start: 999, end: 3001 },
            ZeroBasedHalfOpen { start: 999, end: 3001 },
            adjusted_sequence_length,
            &allele_infos,
            chromosome.clone(),
            true, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        ).unwrap();

        // Calculate global allele frequency
        let allele_frequency = calculate_inversion_allele_frequency(&sample_filter);

        // Define expected allele frequency based on test setup
        let expected_freq = 0.5; // Adjust based on actual calculation
        let allele_frequency_diff = (allele_frequency.unwrap_or(0.0) - expected_freq).abs();
        println!(
            "Filtered global allele frequency difference: {}",
            allele_frequency_diff
        );
        assert!(
            allele_frequency_diff < 1e-6,
            "Filtered global allele frequency is incorrect: expected {:.6}, got {:.6}",
            expected_freq,
            allele_frequency.unwrap_or(0.0)
        );

        // Number of segregating sites
        assert_eq!(result.unwrap().0, 2, "Number of segregating sites should be 2");
    }

    #[test]
    fn test_group1_filtered_number_of_haplotypes() {
        let (variants, sample_names, sample_filter) = setup_group1_test();
        let adjusted_sequence_length = Some(2001); // seq_length = 2001
        let _mask: Option<&[(i64, i64)]> = None;
        let chromosome = "1".to_string();
        let (fasta_file, _cds_regions) = setup_test_data();
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");

        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('C', vec!['G'])),
            Some(('G', vec!['A'])),
        ];
    
        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let _result_group1 = process_variants(
            &variants,
            &sample_names,
            1, // haplotype_group=1
            &sample_filter,
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            adjusted_sequence_length,
            &allele_infos,
            chromosome.clone(),
            true, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        ).unwrap();
    
        let (_segsites, _w_theta, _pi, n_hap, _site_diversity) = match _result_group1 {
            Some(data) => data,
            None => panic!("Expected Some variant data"),
        };
    
        // Number of haplotypes after filtering should be same as before if no filtering applied
        let expected_num_hap_group1_filtered = 3;
        println!(
            "Filtered number of haplotypes for Group 1 (expected {}): {}",
            expected_num_hap_group1_filtered, n_hap
        );
        assert_eq!(
            n_hap, expected_num_hap_group1_filtered,
            "Filtered number of haplotypes for Group 1 is incorrect: expected {}, got {}",
            expected_num_hap_group1_filtered, n_hap
        );
    }

    #[test]
    fn test_group1_filtered_segregating_sites() {
        let (variants, sample_names, sample_filter) = setup_group1_test();
        let adjusted_sequence_length = Some(2001); // seq_length = 2001
        let _mask: Option<&[(i64, i64)]> = None;
        let mut _filtering_stats = FilteringStats::default();
        let chromosome = "1".to_string();
        let (fasta_file, _cds_regions) = setup_test_data();
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");
        
        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('C', vec!['G'])),
            Some(('G', vec!['A'])),
        ];
    
        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let _result_group1 = process_variants(
            &variants,
            &sample_names,
            1, // haplotype_group=1
            &sample_filter,
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            adjusted_sequence_length,
            &allele_infos,
            chromosome.clone(),
            true, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        ).unwrap();
    
        // Correctly unwrap the Option to access the inner tuple
        let (segsites, _w_theta, _pi, _n_hap, _site_diversity) = match _result_group1 {
            Some(data) => data,
            None => panic!("Expected Some variant data"),
        };
    
        let expected_segsites_group1_filtered = 2;
        println!(
            "Filtered number of segregating sites for Group 1 (expected {}): {}",
            expected_segsites_group1_filtered, segsites
        );
        assert_eq!(
            segsites, expected_segsites_group1_filtered,
            "Filtered number of segregating sites for Group 1 is incorrect: expected {}, got {}",
            expected_segsites_group1_filtered, segsites
        );
    }

    #[test]
    fn test_group1_filtered_watterson_theta() {
        let (variants, sample_names, sample_filter) = setup_group1_test();
        let adjusted_sequence_length = Some(2001); // seq_length = 2001
        let _mask: Option<&[(i64, i64)]> = None;
        let mut _filtering_stats = FilteringStats::default();
        let chromosome = "1".to_string();
        let (fasta_file, _cds_regions) = setup_test_data();
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");

        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('C', vec!['G'])),
            Some(('G', vec!['A'])),
        ];
    
        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let _result_group1 = process_variants(
            &variants,
            &sample_names,
            1, // haplotype_group=1
            &sample_filter,
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            ZeroBasedHalfOpen { start: 999, end: 3001 }, // Include position 3000
            adjusted_sequence_length,
            &allele_infos,
            chromosome.clone(),
            true, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        ).unwrap();
    
        // Correctly unwrap the Option to access the inner tuple
        let (_segsites, w_theta, _pi, _n_hap, _site_diversity) = match _result_group1 {
            Some(data) => data,
            None => panic!("Expected Some variant data"),
        };
    
        // Calculate expected Watterson's theta after filtering
        let harmonic_value = harmonic(2); // n-1 =2
        let expected_w_theta_filtered = 2.0 / harmonic_value / 2001.0;
    
        let w_theta_diff_filtered = (w_theta - expected_w_theta_filtered).abs();
        println!(
            "Filtered Watterson's theta difference for Group 1: {}",
            w_theta_diff_filtered
        );
        assert!(
            w_theta_diff_filtered < 1e-6,
            "Filtered Watterson's theta for Group 1 is incorrect: expected {:.6}, got {:.6}",
            expected_w_theta_filtered,
            w_theta
        );
    }

    fn setup_group1_missing_data_test() -> (
        Vec<Variant>,
        Vec<String>,
        HashMap<String, (u8, u8)>,
    ) {
        // Define sample haplotype groupings as per TSV config
        // For haplotype group 1:
        // SAMPLE1: hap1=1
        // SAMPLE2: hap1=0
        // SAMPLE3: hap1=0
        let sample_filter_unfiltered = HashMap::from([
            ("Sample1".to_string(), (0, 1)),
            ("Sample2".to_string(), (0, 1)),
            ("Sample3".to_string(), (0, 0)),
        ]);
    
        // Define variants (for Watterson's theta and pi)
        let variants = vec![
            create_variant(
                1000,
                vec![
                    Some(vec![0, 0]), // Sample1
                    Some(vec![0, 1]), // Sample2
                    Some(vec![1, 1]), // Sample3
                ],
            ),
            create_variant(
                2000,
                vec![
                    Some(vec![0, 0]), // Sample1
                    None,              // Sample2 (missing genotype)
                    Some(vec![0, 0]), // Sample3
                ],
            ), // Missing genotype for Sample2
            create_variant(
                3000,
                vec![
                    Some(vec![0, 1]), // Sample1
                    Some(vec![1, 1]), // Sample2
                    Some(vec![0, 0]), // Sample3
                ],
            ),
        ];
    
        let sample_names = vec![
            "Sample1".to_string(),
            "Sample2".to_string(),
            "Sample3".to_string(),
        ];
    
        (variants, sample_names, sample_filter_unfiltered)
    }

    #[test]
    fn test_group1_missing_data_allele_frequency() {
        let (variants, sample_names, sample_filter_unfiltered) = setup_group1_missing_data_test();
        let chromosome = "1".to_string();
        let (fasta_file, _cds_regions) = setup_test_data();
        let region = ZeroBasedHalfOpen { start: 999, end: 3001 };
        let reference_sequence = read_reference_sequence(fasta_file.path(), "1", region)
            .expect("Failed to read reference sequence");
        
        let allele_infos = vec![
            Some(('A', vec!['T'])),
            Some(('C', vec!['G'])),
            Some(('G', vec!['A'])),
        ];
    
        // Process variants for haplotype_group=1 (Group 1)
        let empty_filtered_positions = HashSet::new();
        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let _result_group1 = process_variants(
            &variants,
            &sample_names,
            1, // haplotype_group=1
            &sample_filter_unfiltered,
            ZeroBasedHalfOpen { start: 999, end: 3001 },
            ZeroBasedHalfOpen { start: 999, end: 3001 },
            None,
            &allele_infos,
            chromosome.clone(),
            true, // is_filtered_set
            &reference_sequence,
            &vec![], // Empty TranscriptAnnotationCDS for test
            &empty_filtered_positions,
            None,
            temp_dir.path(),
            None, None, None,
        ).expect("Failed to process variants");
    
        // Calculate global allele frequency using the revised function (no haplotype_group parameter)
        let allele_frequency_global = calculate_inversion_allele_frequency(&sample_filter_unfiltered);
    
        // Calculate expected global allele frequency based on all haplotypes:
        // SAMPLE1: hap1=1, hap2=0
        // SAMPLE2: hap1=0, hap2=1
        // SAMPLE3: hap1=0, hap2=0
        // Total '1's: 2 (Sample1 hap1 and Sample2 hap2)
        // Total haplotypes: 3 samples * 2 haplotypes each = 6
        let expected_freq_global = 2.0 / 6.0; // 0.333333
        let allele_frequency_diff_global = (allele_frequency_global.unwrap_or(0.0) - expected_freq_global).abs();
        println!(
            "Global allele frequency difference: {}",
            allele_frequency_diff_global
        );
        assert!(
            allele_frequency_diff_global < 1e-6,
            "Global allele frequency is incorrect: expected {:.6}, got {:.6}",
            expected_freq_global,
            allele_frequency_global.unwrap_or(0.0)
        );
    }

    #[test]
    fn test_calculate_adjusted_sequence_length_mask_coordinate_system_fix() {
        // Scenario:
        // Region: 100..200 (1-based inclusive). Length = 101.
        // Mask (BED): 100 101 (0-based half-open). Masks base 100 (0-based) which is base 101 (1-based).
        // Expected Result: Mask removes exactly 1 base (101).
        // Remaining bases: 100 (100..100), 102..200 (99 bases). Total 100.
        // Prior Bug: Subtraction logic was using raw integers (100) and (101).
        //  Start (100) matched mask start (100) -> Left part (100..100) was excluded (start > start logic).
        //  Result was 99.
        // This test ensures the fix (converting 0-based masks to 1-based inclusive) is working.

        let region_start = 100;
        let region_end = 200;
        let mask_regions = vec![(100, 101)]; // 0-based [100, 101) -> 1-based [101, 101]

        use crate::stats::calculate_adjusted_sequence_length;
        let adjusted_len = calculate_adjusted_sequence_length(
            region_start,
            region_end,
            None,
            Some(&mask_regions),
        );

        assert_eq!(
            adjusted_len, 100,
            "Adjusted length should be 100 (101 - 1). Found {}.",
            adjusted_len
        );
    }

    #[test]
    fn test_per_site_falsta_includes_hudson_components() {
        struct DirGuard {
            original: PathBuf,
        }

        impl Drop for DirGuard {
            fn drop(&mut self) {
                std::env::set_current_dir(&self.original)
                    .expect("failed to restore working directory");
            }
        }

        let temp_dir = tempfile::tempdir().expect("failed to create temp dir");
        let original_dir = std::env::current_dir().expect("failed to get current dir");
        std::env::set_current_dir(temp_dir.path()).expect("failed to change working directory");
        let _dir_guard = DirGuard {
            original: original_dir,
        };

        let vcf_dir = temp_dir.path().join("vcf");
        std::fs::create_dir_all(&vcf_dir).expect("failed to create vcf dir");
        let vcf_path = vcf_dir.join("chr1.vcf");
        let mut vcf_file = File::create(&vcf_path).expect("failed to create vcf");
        writeln!(vcf_file, "##fileformat=VCFv4.2").unwrap();
        writeln!(
            vcf_file,
            "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tSampleA\tSampleB"
        )
        .unwrap();
        writeln!(
            vcf_file,
            "chr1\t1\t.\tA\tG\t.\tPASS\t.\tGT:GQ\t0|0:99\t1|1:99"
        )
        .unwrap();
        writeln!(
            vcf_file,
            "chr1\t2\t.\tC\tT\t.\tPASS\t.\tGT:GQ\t0|1:99\t1|0:99"
        )
        .unwrap();
        writeln!(
            vcf_file,
            "chr1\t3\t.\tG\tA\t.\tPASS\t.\tGT:GQ\t1|1:99\t0|0:99"
        )
        .unwrap();

        let fasta_path = temp_dir.path().join("reference.fa");
        let mut fasta_file = File::create(&fasta_path).expect("failed to create fasta");
        writeln!(fasta_file, ">chr1").unwrap();
        writeln!(fasta_file, "ACGTACGTACGT").unwrap();
        drop(fasta_file);

        let fai_path = temp_dir.path().join("reference.fa.fai");
        let mut fai_file = File::create(&fai_path).expect("failed to create fai");
        writeln!(fai_file, "chr1\t12\t6\t12\t13").unwrap();

        let gtf_path = temp_dir.path().join("annotations.gtf");
        let mut gtf_file = File::create(&gtf_path).expect("failed to create gtf");
        writeln!(
            gtf_file,
            "chr1\tsource\tCDS\t1\t3\t.\t+\t0\tgene_id \"GENE1\"; transcript_id \"TRANS1\"; gene_name \"GENE1\";"
        )
        .unwrap();

        let config_path = temp_dir.path().join("config.tsv");
        let mut config_file = File::create(&config_path).expect("failed to create config");
        writeln!(
            config_file,
            "seqnames\tstart\tend\tPOS\torig_ID\tverdict\tcateg\tSampleA\tSampleB"
        )
        .unwrap();
        writeln!(config_file, "chr1\t1\t3\t1\tid1\tpass\tinv\t0|0\t1|1").unwrap();

        let config_entries = parse_config_file(&config_path).expect("failed to parse config");

        struct ProgressGuard;

        impl Drop for ProgressGuard {
            fn drop(&mut self) {
                crate::progress::finish_all();
            }
        }

        crate::progress::init_global_progress(config_entries.len());
        let _progress_guard = ProgressGuard;

        let args = Args {
            vcf_folder: vcf_dir.to_string_lossy().into_owned(),
            chr: None,
            region: None,
            config_file: None,
            output_file: None,
            min_gq: 30,
            mask_file: None,
            allow_file: None,
            reference_path: fasta_path.to_string_lossy().into_owned(),
            gtf_path: gtf_path.to_string_lossy().into_owned(),
            enable_pca: false,
            pca_components: 10,
            pca_output: "pca_results.tsv".to_string(),
            enable_fst: true,
            fst_populations: None,
            exclude: None,
        };

        let output_csv = temp_dir.path().join("results.csv");
        let exclusion_set = HashSet::new();
        process_config_entries(
            &config_entries,
            &args.vcf_folder,
            &output_csv,
            args.min_gq,
            None,
            None,
            &args,
            &exclusion_set,
            temp_dir.path(),
        )
        .expect("process_config_entries failed");

        let falsta_path = temp_dir
            .path()
            .join("per_site_fst_output.falsta.gz");
        assert!(falsta_path.exists(), "per-site falsta was not created");

        let file = std::fs::File::open(&falsta_path).expect("failed to open falsta file");
        let mut decoder = GzDecoder::new(file);
        let mut contents = String::new();
        decoder
            .read_to_string(&mut contents)
            .expect("failed to read per-site falsta");
        let lines: Vec<&str> = contents.lines().collect();

        let fst_header = ">hudson_pairwise_fst_hap_0v1_chr_1_start_1_end_3";
        let fst_index = lines
            .iter()
            .position(|line| *line == fst_header)
            .expect("missing hudson per-site fst header");
        let fst_values: Vec<f64> = lines[fst_index + 1]
            .split(',')
            .map(|v| v.parse::<f64>().expect("invalid FST value"))
            .collect();
        assert_eq!(fst_values.len(), 3);
        assert!((fst_values[0] - 1.0).abs() < 1e-6);
        assert!((fst_values[1] + 1.0).abs() < 1e-6, "FST should retain negative values");
        assert!((fst_values[2] - 1.0).abs() < 1e-6);

        let numerator_header = ">hudson_pairwise_fst_hap_0v1_numerator_chr_1_start_1_end_3";
        let numerator_index = lines
            .iter()
            .position(|line| *line == numerator_header)
            .expect("missing hudson numerator header");
        let numerator_values: Vec<f64> = lines[numerator_index + 1]
            .split(',')
            .map(|v| v.parse::<f64>().expect("invalid numerator value"))
            .collect();
        assert_eq!(numerator_values.len(), 3);
        assert!((numerator_values[0] - 1.0).abs() < 1e-6);
        assert!((numerator_values[1] + 0.5).abs() < 1e-6);
        assert!((numerator_values[2] - 1.0).abs() < 1e-6);

        let denominator_header = ">hudson_pairwise_fst_hap_0v1_denominator_chr_1_start_1_end_3";
        let denominator_index = lines
            .iter()
            .position(|line| *line == denominator_header)
            .expect("missing hudson denominator header");
        let denominator_values: Vec<f64> = lines[denominator_index + 1]
            .split(',')
            .map(|v| v.parse::<f64>().expect("invalid denominator value"))
            .collect();
        assert_eq!(denominator_values.len(), 3);
        assert!((denominator_values[0] - 1.0).abs() < 1e-6);
        assert!((denominator_values[1] - 0.5).abs() < 1e-6);
        assert!((denominator_values[2] - 1.0).abs() < 1e-6);
    }
}
